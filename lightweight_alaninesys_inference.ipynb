{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Alaninesys Inference\n",
    "\n",
    "This notebook provides a minimal implementation for running inference on alaninesys models.\n",
    "It loads configs, models, and generates 500 samples without plotting or energy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 30 22:59:20 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.77                 Driver Version: 565.77         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40                     Off |   00000000:45:00.0 Off |                    0 |\n",
      "| N/A   53C    P0             72W /  300W |       1MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n",
      "\n",
      "****** PyMBAR will use 64-bit JAX! *******\n",
      "* JAX is currently set to 32-bit bitsize *\n",
      "* which is its default.                  *\n",
      "*                                        *\n",
      "* PyMBAR requires 64-bit mode and WILL   *\n",
      "* enable JAX's 64-bit mode when called.  *\n",
      "*                                        *\n",
      "* This MAY cause problems with other     *\n",
      "* Uses of JAX in the same code.          *\n",
      "******************************************\n",
      "\n",
      "/net/galaxy/home/koes/jmc530/.local/lib/python3.10/site-packages/Bio/Application/__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
      "\n",
      "Due to the on going maintenance burden of keeping command line application\n",
      "wrappers up to date, we have decided to deprecate and eventually remove these\n",
      "modules.\n",
      "\n",
      "We instead now recommend building your command line and invoking it directly\n",
      "with the subprocess module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import yaml\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(\"./BoltzNCE/\")\n",
    "from BoltzNCE.utils.utils import load_models\n",
    "from BoltzNCE.dataset.alsys_dataloader import alaninesys_featurizer\n",
    "from BoltzNCE.models.interpolant import Interpolant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config from /net/galaxy/home/koes/jmc530/koes_lab/BoltzNCE/BoltzNCE/saved_models/trained_vector_9_layer_al6_mc.yaml\n"
     ]
    }
   ],
   "source": [
    "# Set config path - modify this to your config file\n",
    "config_path = \"/net/galaxy/home/koes/jmc530/koes_lab/BoltzNCE/BoltzNCE/saved_models/trained_vector_9_layer_al6_mc.yaml\"  # UPDATE THIS PATH\n",
    "\n",
    "# Load config\n",
    "with open(config_path, 'r') as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Loaded config from {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Parameters and Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology loaded with 63 particles, dimension: 189\n"
     ]
    }
   ],
   "source": [
    "# Extract data parameters\n",
    "scaling = 30.0\n",
    "data_path = args['dataloader']['data_path']\n",
    "split = args['dataloader']['split']\n",
    "\n",
    "# Load topology and initial features\n",
    "topology, h_initial = alaninesys_featurizer(data_path, split=split)\n",
    "\n",
    "# Setup adjacency list and atom types\n",
    "adj_list = torch.from_numpy(np.array([(b.atom1.index, b.atom2.index) for b in topology.bonds], dtype=np.int32))\n",
    "atom_dict = {\"C\": 0, \"H\": 1, \"N\": 2, \"O\": 3, \"S\": 4}\n",
    "atom_types = []\n",
    "for atom_name in topology.atoms:\n",
    "    atom_types.append(atom_name.name[0])\n",
    "atom_types = torch.from_numpy(np.array([atom_dict[atom_type] for atom_type in atom_types]))\n",
    "\n",
    "# Setup dimensions\n",
    "dim = h_initial.shape[0] * 3\n",
    "n_particles = h_initial.shape[0]\n",
    "args['dim'] = dim\n",
    "\n",
    "print(f\"Topology loaded with {n_particles} particles, dimension: {dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Interpolant Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolant arguments updated\n"
     ]
    }
   ],
   "source": [
    "def update_interpolant_args(args):\n",
    "    \"\"\"Update interpolant arguments with integration parameters\"\"\"\n",
    "    args['interpolant']['rtol'] = args['rtol']\n",
    "    args['interpolant']['atol'] = args['atol'] \n",
    "    args['interpolant']['tmin'] = args['tmin']\n",
    "    args['interpolant']['dim'] = args['dim']\n",
    "    args['interpolant']['num_particles'] = args['dim'] // 3\n",
    "    return args\n",
    "\n",
    "# Set default values if not in config\n",
    "args['rtol'] = 1e-3\n",
    "args['atol'] = 1e-3\n",
    "args['tmin'] = args.get('tmin', 0.0)\n",
    "\n",
    "# Update interpolant arguments\n",
    "args = update_interpolant_args(args)\n",
    "\n",
    "print(\"Interpolant arguments updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in vector field model: 1209431\n",
      "Loaded vector field model from /net/galaxy/home/koes/rishal/nce/BoltzNCE/saved_models/trained_vector_9_layer_al6_mc.pt\n",
      "Models loaded and set to evaluation mode\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "potential_model, vector_field, interpolant_obj = load_models(\n",
    "    args, \n",
    "    h_initial=h_initial, \n",
    "    potential=args['model_type']=='potential'\n",
    ")\n",
    "\n",
    "# Set models to evaluation mode\n",
    "if potential_model is not None:\n",
    "    potential_model.eval()\n",
    "vector_field.eval()\n",
    "\n",
    "print(\"Models loaded and set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 μs, sys: 5 μs, total: 22 μs\n",
      "Wall time: 5.01 μs\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "def gen_samples(n_samples, n_sample_batches, interpolant_obj, integral_type='ode'):\n",
    "    \"\"\"\n",
    "    Generate samples using the interpolant object.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples per batch\n",
    "        n_sample_batches: Number of batches\n",
    "        interpolant_obj: Interpolant object for sampling\n",
    "        integral_type: Type of integration ('ode' or 'ode_divergence')\n",
    "    \n",
    "    Returns:\n",
    "        samples_np: Generated samples as numpy array\n",
    "        dlogp_all: Log probabilities (divergence info)\n",
    "    \"\"\"\n",
    "    samples_np = np.empty(shape=(0))\n",
    "    dlogp_all = []\n",
    "    \n",
    "    # Store original interpolant type and switch to integration type\n",
    "    interpolant_placeholder = interpolant_obj.interpolant_type\n",
    "    interpolant_obj.interpolant_type = interpolant_obj.integration_interpolant\n",
    "    \n",
    "    for i in tqdm.tqdm(range(n_sample_batches), desc=\"Generating samples\"):\n",
    "        if integral_type == 'ode':\n",
    "            samples = interpolant_obj.ode_integral(n_samples)\n",
    "        elif integral_type == 'ode_divergence':\n",
    "            samples, logp_samples = interpolant_obj.ode_divergence_integral(n_samples)\n",
    "            dlogp_all.append(logp_samples.cpu().detach().numpy())\n",
    "        else:\n",
    "            raise ValueError(\"integral_type not recognized\")\n",
    "        \n",
    "        samples_np = np.append(samples_np, samples.detach().cpu().numpy())\n",
    "    \n",
    "    # Process divergence info\n",
    "    if len(dlogp_all) > 0:\n",
    "        dlogp_all = np.concatenate(dlogp_all, axis=0)\n",
    "    else:\n",
    "        # Uniform weights when no divergence\n",
    "        dlogp_all = np.zeros((samples_np.shape[0], 1), dtype=np.float32)\n",
    "    \n",
    "    samples_np = samples_np.reshape(-1, interpolant_obj.dim)\n",
    "    \n",
    "    # Restore original interpolant type\n",
    "    interpolant_obj.interpolant_type = interpolant_placeholder\n",
    "    \n",
    "    return samples_np, dlogp_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## generating initial samples\n",
      "Generating 100 samples in 1 batches using ode_divergence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 1/1 [1:13:10<00:00, 4390.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated samples shape: (100, 189)\n",
      "Divergence info shape: (100, 1)\n",
      "Inference completed successfully!\n",
      "CPU times: user 19min 36s, sys: 53min 38s, total: 1h 13min 15s\n",
      "Wall time: 1h 13min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "# Set inference parameters (matching original script)\n",
    "n_samples = 100  # Total samples to generate\n",
    "n_sample_batches = 1  # Number of batches (as in original script)\n",
    "divergence = True  # Set to True to evaluate divergence (as in original script)\n",
    "\n",
    "# Determine integral type (matching original script logic)\n",
    "integral_type = 'ode'\n",
    "if divergence == True:\n",
    "    integral_type = 'ode_divergence'\n",
    "\n",
    "print(f\"########## generating initial samples\")\n",
    "print(f\"Generating {n_samples} samples in {n_sample_batches} batches using {integral_type}...\")\n",
    "\n",
    "# Generate samples (matching original script call)\n",
    "samples_np, dlogf_np = gen_samples(\n",
    "    n_samples=n_samples,\n",
    "    n_sample_batches=n_sample_batches,\n",
    "    interpolant_obj=interpolant_obj,\n",
    "    integral_type=integral_type\n",
    ")\n",
    "\n",
    "print(f\"Generated samples shape: {samples_np.shape}\")\n",
    "print(f\"Divergence info shape: {dlogf_np.shape}\")\n",
    "print(\"Inference completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results not saved (set save_results=True to save)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save generated samples\n",
    "save_results = False  # Set to True if you want to save\n",
    "\n",
    "if save_results:\n",
    "    save_prefix = './generated/'\n",
    "    np.save(f'{save_prefix}samples.npy', samples_np)\n",
    "    np.save(f'{save_prefix}dlogp.npy', dlogp_np)\n",
    "    print(f\"Results saved to {save_prefix}\")\n",
    "else:\n",
    "    print(\"Results not saved (set save_results=True to save)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
