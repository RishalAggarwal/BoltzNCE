config_save_name: saved_models/trained_potential_trig_graphormer_1b8ld256_2.yaml
dataloader:
  batch_size: 512
  num_workers: 8
  scaling: 1.0
  shuffle: true
dim: 66
ema: false
ema_model:
  beta: 0.999
  update_every: 10
  update_model_with_ema_every: null
graphormer:
  activation_dropout: 0.0
  attention_dropout: 0.0
  attention_heads: 32
  blocks: 1
  dropout: 0.0
  embed_dim: 256
  ffn_embed_dim: 256
  input_dropout: 0.0
  num_kernel: 50
gvp:
  n_hidden: 64
  n_message_gvps: 1
  n_update_gvps: 1
  n_vec: 16
  use_dst_feats: false
  vector_gating: true
interpolant:
  dim: 66
  endpoint: false
  interpolant_type: trig
  integration_interpolant: linear
  n_dimensions: 3
  num_particles: 22
  ot: false
  scaling: 1.0
  self_conditioning: false
load_potential_checkpoint: saved_models/trained_potential_trig_graphormer_1b8ld256_2.pt
load_vector_field_checkpoint: saved_models/trained_vector_5_layer_ot_ema.pt
model_type: potential
n_dimensions: 3
num_particles: 22
optimizer:
  lr: 0.001
  weight_decay: 0.0
optimizer_type: adam
potential_model:
  num_layers: 8
  num_particles: 22
potential_type: graphormer
save_potential_checkpoint: saved_models/trained_potential_trig_graphormer_1b8ld256_2.pt
save_vector_field_checkpoint: saved_models/trained_vector_5_layer_ot_ema.pt
scheduler:
  factor: 0.5
  min_lr: 1.0e-05
  mode: min
  patience: 30
  verbose: true
train_potential:
  nce_weight: 1.0
  num_negatives: 1
  window_size: 0.025
train_vector:
  endpoint: false
  self_conditioning: false
training:
  grad_norm: null
  num_epochs: 1000
vector_field_model:
  n_coord_gvps: 1
  n_layers: 5
  num_particles: 22
  self_conditioning: false
wandb: true
wandb_name: potential_trainining_trig_graphormer_1b8ld256_2
wandb_project: BoltzNCE_alanine
