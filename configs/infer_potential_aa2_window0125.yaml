config: configs/train_potential_aa2_window0125.yaml
config_save_name: saved_models/trained_potential_trig_graphormer_aa2_window0125.yaml
dataloader:
  batch_size: 256
  data_path: data/2AA-1-large/
  kabsch: true
  num_workers: 8
  shuffle: true
  split: gen
ema: false
ema_model:
  beta: 0.999
  update_every: 10
  update_model_with_ema_every: null
graphormer:
  activation_dropout: 0.0
  attention_dropout: 0.0
  attention_heads: 32
  blocks: 1
  dropout: 0.0
  embed_dim: 512
  ffn_embed_dim: 512
  input_dropout: 0.0
  num_kernel: 50
gvp:
  n_hidden: 128
  n_message_gvps: 1
  n_update_gvps: 1
  n_vec: 16
  use_dst_feats: false
  vector_gating: true
interpolant:
  dim: 66
  integration_interpolant: linear
  interpolant_type: trig
  n_dimensions: 3
  num_particles: 22
  ot: false
load_potential_checkpoint: saved_models/trained_potential_trig_graphormer_aa2_window0125.pt
load_vector_field_checkpoint: saved_models/trained_vector_9_layer_kabsch_aa2_ema.pt
model_type: potential
n_dimensions: 3
num_particles: 22
optimizer:
  lr: 0.001
  weight_decay: 0.0
optimizer_type: adam
potential_model:
  num_features: 76
  num_layers: 12
  num_particles: 22
potential_type: graphormer
save_potential_checkpoint: saved_models/trained_potential_trig_graphormer_aa2_window0125.pt
save_vector_field_checkpoint: null
scheduler:
  factor: 0.5
  min_lr: 1.0e-05
  mode: min
  patience: 30
  verbose: true
train_potential:
  nce_weight: 1.0
  num_negatives: 1
  window_size: 0.0125
train_vector:
  endpoint: false
  self_conditioning: false
  tweight_max: 1.5
training:
  grad_norm: null
  num_epochs: 100
vector_field_model:
  n_coord_gvps: 1
  n_features: 76
  n_layers: 9
wandb: true
wandb_name: potential_trainining_trig_graphormer_aa2_window0125
wandb_project: BoltzNCE_aa2
